name: smoke-tests-bare-metal

on:
  push:
    branches: ["main", "smoke-tests"]
    paths-ignore:
      - "**.md"
      - "docs/**"
  pull_request:
    branches: ["main"]
    paths-ignore:
      - "**.md"
      - "docs/**"
  workflow_dispatch:
    inputs:
      branch-to-checkout:
        type: string
        default: "main"
        required: false
        description: "Branch name to use"
      list_tests:
        type: choice
        required: false
        description: "List all tests before running"
        options:
          - "true"
          - "false"
      markers:
        type: string
        default: "smoke"
        required: false
        description: "Markers to use for pytest"

# Add workflow-level concurrency to prevent duplicated runs
concurrency:
  group: smoke-tests-${{ github.workflow }}-${{ github.ref_name || github.head_ref }}
  cancel-in-progress: true

env:
  BUILD_TYPE: "Release"
  DPDK_VERSION: "23.11"
  DPDK_REBUILD: "false"
  MEDIA_PATH: "/mnt/media"
  BUILD_DIR: "${{ github.workspace }}/_build"
  MCM_BINARIES_DIR: "./mcm-binaries"
  MEDIA_PROXY: "./mcm-binaries/media_proxy"
  MESH_AGENT: "./mcm-binaries/mesh-agent"
  MCM_FFMPEG_7_0: ./mcm-binaries/ffmpeg-7-0/ffmpeg
  MTL_FFMPEG_7_0: ./mtl-binaries/ffmpeg-7-0/ffmpeg
  MCM_FFMPEG_6_1: ./mcm-binaries/ffmpeg-6-1/ffmpeg
  MTL_FFMPEG_6_1: ./mtl-binaries/ffmpeg-6-1/ffmpeg
  LOG_DIR: "${{ github.workspace }}/logs"

permissions:
  contents: read

jobs:
  call-base-build:
    uses: ./.github/workflows/base_build.yml
    with:
      branch: ${{ github.event_name == 'push' && github.ref_name || github.event.inputs.branch-to-checkout || 'main' }}
    # Remove job-level concurrency as it's now handled at the workflow level

  validation-prepare-setup-mcm:
    runs-on: [Linux, self-hosted]
    needs: call-base-build
    timeout-minutes: 60
    outputs:
      pipenv-activate: ${{ steps.pipenv-install.outputs.VIRTUAL_ENV }}
    # Remove job-level concurrency as it's now handled at the workflow level
    steps:
      - name: "preparation: Harden Runner"
        uses: step-security/harden-runner@6c439dc8bdf85cadbbce9ed30d1c7b959517bc49 # v2.12.2
        with:
          egress-policy: audit
      - name: "preparation: Restore valid repository owner and print env"
        if: always()
        run: |
          sudo chown -R "${USER}" "$(pwd)" || true
          env | grep BUILD_ || true
          env | grep DPDK_ || true
      - name: "preparation: Checkout MCM"
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ github.event_name == 'push' && github.ref_name || github.event.inputs.branch-to-checkout || 'main' }}
      - name: Install RxTxApp dependencies
        run: sudo apt-get update && sudo apt-get install -y libjansson-dev
      - name: "build RxTxApp"
        working-directory: ${{ github.workspace }}/tests/tools/TestApp
        run: |
          mkdir build && cd build && \
          cmake .. && \
          make
      - name: "clone FFMPEG repository"
        run: |
          echo "Cloning FFMPEG repository"
      - name: "clone MTL repository"
        run: |
          echo "Cloning MTL repository"
      - name: "build MTL FFMPEG"
        run: |
          echo "Building MTL FFMPEG"
      - name: "installation: Install pipenv environment"
        working-directory: tests/validation
        id: pipenv-install
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install -r requirements.txt
          echo "VIRTUAL_ENV=$PWD/venv/bin/activate" >> "$GITHUB_ENV"
      - name: "add user name to environment and config"
        run: |
          echo "USER=${USER}" >> "$GITHUB_ENV"
          sed -i "s/{{ USER }}/root/g" tests/validation/configs/topology_config_workflow.yaml
          sed -i "s|{{ KEY_PATH }}|/home/${USER}/.ssh/mcm_key|g" tests/validation/configs/topology_config_workflow.yaml
          sed -i "s|{{ MCM_PATH }}|${{ github.workspace }}|g" tests/validation/configs/topology_config_workflow.yaml
          sed -i "s|{{ LOG_PATH }}|${{ env.LOG_DIR }}|g" tests/validation/configs/test_config_workflow.yaml
  validation-run-tests:
    needs: validation-prepare-setup-mcm
    runs-on: [Linux, self-hosted]
    timeout-minutes: 60
    concurrency:
      group: run-tests-${{ github.head_ref || github.ref_name }}
      cancel-in-progress: true
    if: github.event_name != 'pull_request' || github.event.pull_request.head.repo.full_name != github.repository
    env:
      PYTEST_RETRIES: "3"
      MARKERS: ${{ github.event.inputs.markers || 'smoke' }}
      LIST_TESTS: ${{ github.event.inputs.list_tests || 'true' }}
    steps:
      - name: "preparation: Kill pytest routines"
        run: |
          sudo killall -SIGINT pipenv || true
          sudo killall -SIGINT pytest || true
      - name: "list all tests marked with ${{ env.MARKERS }}"
        if: ${{ env.LIST_TESTS == 'true' }}
        run: |
          sudo tests/validation/venv/bin/python3 -m pytest \
            --collect-only --quiet ./tests/validation/functional/ \
            -m "${{ env.MARKERS }}"
      - name: "execution: Run validation-bare-metal tests in virtual environment"
        run: |
          sudo tests/validation/venv/bin/python3 -m pytest \
            --topology_config=tests/validation/configs/topology_config_workflow.yaml \
            --test_config=tests/validation/configs/test_config_workflow.yaml \
            ./tests/validation/functional/ \
            --template=html/index.html --report=report.html \
            -m "${{ env.MARKERS }}"
      - name: "upload logs"
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3
        with:
          name: smoke-tests-logs
          path: |
            ${{ env.LOG_DIR }}/*
      - name: "upload report"
        uses: actions/upload-artifact@b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882 # v4.4.3
        with:
          name: smoke-tests-report
          path: |
            report.html
      - name: "Add report to summary"
        if: always()
        run: |
          {
            echo "## Smoke Tests Report"
            echo ""

            # Check if report exists
            if [ -f "report.html" ]; then
              # Extract relevant parts from the HTML report
              echo "### Test Results Summary"
              
              # Extract pass/fail counts with proper quoting
              PASSED="$(grep -o "passed=[0-9]*" report.html | cut -d= -f2)"
              FAILED="$(grep -o "failed=[0-9]*" report.html | cut -d= -f2)"
              SKIPPED="$(grep -o "skipped=[0-9]*" report.html | cut -d= -f2)"
              
              # Add summary stats
              echo "| Status | Count |"
              echo "| ------ | ----- |"
              echo "| ✅ Passed | ${PASSED:-0} |"
              echo "| ❌ Failed | ${FAILED:-0} |"
              echo "| ⏭️ Skipped | ${SKIPPED:-0} |"
              echo ""
              
              # Add link to full report artifact
              echo "📄 [View Full HTML Report](https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID})"
            else
              echo "❌ No report.html file was generated"
            fi
          } >> "$GITHUB_STEP_SUMMARY"
